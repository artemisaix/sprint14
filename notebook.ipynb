{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El servicio de venta de autos usados Rusty Bargain está desarrollando una aplicación para atraer nuevos clientes. Gracias a esa app, puedes averiguar rápidamente el valor de mercado de tu coche. Tienes acceso al historial: especificaciones técnicas, versiones de equipamiento y precios. Tienes que crear un modelo que determine el valor de mercado.\n",
    "A Rusty Bargain le interesa:\n",
    "- la calidad de la predicción;\n",
    "- la velocidad de la predicción;\n",
    "- el tiempo requerido para el entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparación de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "# Entrenamiento y evaluación de modelos\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import lightgbm as lgb\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Información general del DataFrame:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 354369 entries, 0 to 354368\n",
      "Data columns (total 16 columns):\n",
      " #   Column             Non-Null Count   Dtype \n",
      "---  ------             --------------   ----- \n",
      " 0   DateCrawled        354369 non-null  object\n",
      " 1   Price              354369 non-null  int64 \n",
      " 2   VehicleType        316879 non-null  object\n",
      " 3   RegistrationYear   354369 non-null  int64 \n",
      " 4   Gearbox            334536 non-null  object\n",
      " 5   Power              354369 non-null  int64 \n",
      " 6   Model              334664 non-null  object\n",
      " 7   Mileage            354369 non-null  int64 \n",
      " 8   RegistrationMonth  354369 non-null  int64 \n",
      " 9   FuelType           321474 non-null  object\n",
      " 10  Brand              354369 non-null  object\n",
      " 11  NotRepaired        283215 non-null  object\n",
      " 12  DateCreated        354369 non-null  object\n",
      " 13  NumberOfPictures   354369 non-null  int64 \n",
      " 14  PostalCode         354369 non-null  int64 \n",
      " 15  LastSeen           354369 non-null  object\n",
      "dtypes: int64(7), object(9)\n",
      "memory usage: 43.3+ MB\n",
      "None\n",
      "\n",
      "Resumen estadístico de las variables numéricas:\n",
      "               Price  RegistrationYear          Power        Mileage  \\\n",
      "count  354369.000000     354369.000000  354369.000000  354369.000000   \n",
      "mean     4416.656776       2004.234448     110.094337  128211.172535   \n",
      "std      4514.158514         90.227958     189.850405   37905.341530   \n",
      "min         0.000000       1000.000000       0.000000    5000.000000   \n",
      "25%      1050.000000       1999.000000      69.000000  125000.000000   \n",
      "50%      2700.000000       2003.000000     105.000000  150000.000000   \n",
      "75%      6400.000000       2008.000000     143.000000  150000.000000   \n",
      "max     20000.000000       9999.000000   20000.000000  150000.000000   \n",
      "\n",
      "       RegistrationMonth  NumberOfPictures     PostalCode  \n",
      "count      354369.000000          354369.0  354369.000000  \n",
      "mean            5.714645               0.0   50508.689087  \n",
      "std             3.726421               0.0   25783.096248  \n",
      "min             0.000000               0.0    1067.000000  \n",
      "25%             3.000000               0.0   30165.000000  \n",
      "50%             6.000000               0.0   49413.000000  \n",
      "75%             9.000000               0.0   71083.000000  \n",
      "max            12.000000               0.0   99998.000000  \n",
      "\n",
      "Cantidad de valores nulos por columna:\n",
      "DateCrawled              0\n",
      "Price                    0\n",
      "VehicleType          37490\n",
      "RegistrationYear         0\n",
      "Gearbox              19833\n",
      "Power                    0\n",
      "Model                19705\n",
      "Mileage                  0\n",
      "RegistrationMonth        0\n",
      "FuelType             32895\n",
      "Brand                    0\n",
      "NotRepaired          71154\n",
      "DateCreated              0\n",
      "NumberOfPictures         0\n",
      "PostalCode               0\n",
      "LastSeen                 0\n",
      "dtype: int64\n",
      "\n",
      "Valores nulos después de la limpieza:\n",
      "Price                0\n",
      "VehicleType          0\n",
      "RegistrationYear     0\n",
      "Gearbox              0\n",
      "Power                0\n",
      "Model                0\n",
      "Mileage              0\n",
      "RegistrationMonth    0\n",
      "FuelType             0\n",
      "Brand                0\n",
      "NotRepaired          0\n",
      "dtype: int64\n",
      "\n",
      "Preparación de datos completada. Listo para el entrenamiento de modelos.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Cargar el dataset\n",
    "df = pd.read_csv('datasets/car_data.csv')\n",
    "\n",
    "# Mostrar las primeras filas para verificar la carga\n",
    "df.head()\n",
    "\n",
    "# Revisión y preparación de los datos\n",
    "\n",
    "# Revisar información general del DataFrame\n",
    "print(\"Información general del DataFrame:\")\n",
    "print(df.info())\n",
    "print(\"\\nResumen estadístico de las variables numéricas:\")\n",
    "print(df.describe())\n",
    "\n",
    "# Revisar valores nulos\n",
    "print(\"\\nCantidad de valores nulos por columna:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Eliminar columnas que no aportan valor al modelo\n",
    "columnas_a_eliminar = ['DateCrawled', 'DateCreated', 'NumberOfPictures', 'PostalCode', 'LastSeen']\n",
    "df = df.drop(columns=columnas_a_eliminar)\n",
    "\n",
    "# Eliminar duplicados si existen\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "# Corregir valores atípicos y erróneos en 'RegistrationYear'\n",
    "# Consideramos años razonables entre 1950 y 2016 (según el dataset)\n",
    "df = df[(df['RegistrationYear'] >= 1950) & (df['RegistrationYear'] <= 2016)]\n",
    "\n",
    "# Corregir valores atípicos en 'Price'\n",
    "# Eliminamos precios menores a 100 y mayores a 50000 euros (ajustar si es necesario)\n",
    "df = df[(df['Price'] >= 100) & (df['Price'] <= 50000)]\n",
    "\n",
    "# Corregir valores atípicos en 'Power'\n",
    "# Eliminamos potencias menores a 10 CV y mayores a 500 CV (ajustar si es necesario)\n",
    "df = df[(df['Power'] >= 10) & (df['Power'] <= 500)]\n",
    "\n",
    "# Rellenar valores nulos en variables categóricas con 'unknown'\n",
    "columnas_categoricas = ['VehicleType', 'Gearbox', 'Model', 'FuelType', 'Brand', 'NotRepaired']\n",
    "for columna in columnas_categoricas:\n",
    "    df[columna] = df[columna].fillna('unknown')\n",
    "\n",
    "# Rellenar valores nulos en variables numéricas con la mediana\n",
    "columnas_numericas = ['Mileage', 'RegistrationMonth']\n",
    "for columna in columnas_numericas:\n",
    "    df[columna] = df[columna].fillna(df[columna].median())\n",
    "\n",
    "# Comprobar que no queden valores nulos\n",
    "print(\"\\nValores nulos después de la limpieza:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Codificar variables categóricas para modelos que lo requieran (por ejemplo, regresión lineal)\n",
    "# Usaremos One-Hot Encoding para las variables categóricas principales\n",
    "df_ohe = pd.get_dummies(df, columns=columnas_categoricas, drop_first=True)\n",
    "\n",
    "# Separar variables objetivo y características\n",
    "X = df_ohe.drop('Price', axis=1)\n",
    "y = df_ohe['Price']\n",
    "\n",
    "# Dividir el dataset en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Escalar las variables numéricas para modelos sensibles a la escala (por ejemplo, regresión lineal)\n",
    "scaler = StandardScaler()\n",
    "columnas_a_escalar = ['RegistrationYear', 'Power', 'Mileage', 'RegistrationMonth']\n",
    "X_train[columnas_a_escalar] = scaler.fit_transform(X_train[columnas_a_escalar])\n",
    "X_test[columnas_a_escalar] = scaler.transform(X_test[columnas_a_escalar])\n",
    "\n",
    "print(\"\\nPreparación de datos completada. Listo para el entrenamiento de modelos.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Comentarios**\n",
    " \n",
    " En esta sección, se realizó una limpieza y preparación exhaustiva de los datos, corrigiendo valores atípicos y nulos, y codificando las variables categóricas. Además, se dividió el conjunto de datos en entrenamiento y prueba, y se escalaron las variables numéricas relevantes. \n",
    "\n",
    " Gracias a estos pasos, los datos están listos para ser utilizados en el entrenamiento de distintos modelos de regresión, asegurando así una mayor calidad y fiabilidad en los resultados obtenidos posteriormente.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento del modelo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando modelo de Regresión Lineal...\n",
      "Regresión Lineal - RECM: 2577.29, Tiempo de entrenamiento: 4.22s, Tiempo de predicción: 0.1037s\n",
      "\n",
      "Entrenando modelo Árbol de Decisión...\n",
      "Árbol de Decisión - RECM: 2060.63, Tiempo de entrenamiento: 4.48s, Tiempo de predicción: 0.0722s\n",
      "\n",
      "Entrenando modelo Bosque Aleatorio...\n",
      "Bosque Aleatorio - RECM: 1618.31, Tiempo de entrenamiento: 93.81s, Tiempo de predicción: 0.6434s\n",
      "\n",
      "Entrenando modelo LightGBM con ajuste de hiperparámetros...\n",
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004943 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 911\n",
      "[LightGBM] [Info] Number of data points in the train set: 203995, number of used features: 292\n",
      "[LightGBM] [Info] Start training from score 4856.355808\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "LightGBM - RECM: 1613.64, Mejor combinación: {'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 200}, Tiempo de entrenamiento: 32.14s, Tiempo de predicción: 0.1579s\n"
     ]
    }
   ],
   "source": [
    "# 1. Regresión Lineal\n",
    "print(\"Entrenando modelo de Regresión Lineal...\")\n",
    "start = time.time()\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "lr_train_time = time.time() - start\n",
    "\n",
    "start = time.time()\n",
    "y_pred_lr = lr.predict(X_test)\n",
    "lr_pred_time = time.time() - start\n",
    "\n",
    "rmse_lr = np.sqrt(mean_squared_error(y_test, y_pred_lr))\n",
    "print(f\"Regresión Lineal - RECM: {rmse_lr:.2f}, Tiempo de entrenamiento: {lr_train_time:.2f}s, Tiempo de predicción: {lr_pred_time:.4f}s\\n\")\n",
    "\n",
    "# 2. Árbol de Decisión\n",
    "print(\"Entrenando modelo Árbol de Decisión...\")\n",
    "start = time.time()\n",
    "dt = DecisionTreeRegressor(random_state=42)\n",
    "dt.fit(X_train, y_train)\n",
    "dt_train_time = time.time() - start\n",
    "\n",
    "start = time.time()\n",
    "y_pred_dt = dt.predict(X_test)\n",
    "dt_pred_time = time.time() - start\n",
    "\n",
    "rmse_dt = np.sqrt(mean_squared_error(y_test, y_pred_dt))\n",
    "print(f\"Árbol de Decisión - RECM: {rmse_dt:.2f}, Tiempo de entrenamiento: {dt_train_time:.2f}s, Tiempo de predicción: {dt_pred_time:.4f}s\\n\")\n",
    "\n",
    "# 3. Bosque Aleatorio\n",
    "print(\"Entrenando modelo Bosque Aleatorio...\")\n",
    "start = time.time()\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "rf.fit(X_train, y_train)\n",
    "rf_train_time = time.time() - start\n",
    "\n",
    "start = time.time()\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "rf_pred_time = time.time() - start\n",
    "\n",
    "rmse_rf = np.sqrt(mean_squared_error(y_test, y_pred_rf))\n",
    "print(f\"Bosque Aleatorio - RECM: {rmse_rf:.2f}, Tiempo de entrenamiento: {rf_train_time:.2f}s, Tiempo de predicción: {rf_pred_time:.4f}s\\n\")\n",
    "\n",
    "# 4. LightGBM con ajuste de hiperparámetros\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "print(\"Entrenando modelo LightGBM con ajuste de hiperparámetros...\")\n",
    "\n",
    "# Definir el modelo base\n",
    "lgbm = lgb.LGBMRegressor(objective='regression', random_state=42)\n",
    "\n",
    "# Definir los hiperparámetros a probar\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'learning_rate': [0.05, 0.1],\n",
    "    'max_depth': [4, 6, 8]\n",
    "}\n",
    "\n",
    "# Búsqueda de hiperparámetros con validación cruzada\n",
    "grid = GridSearchCV(\n",
    "    estimator=lgbm,\n",
    "    param_grid=param_grid,\n",
    "    scoring='neg_root_mean_squared_error',  # Para RMSE\n",
    "    cv=3,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "start = time.time()\n",
    "grid.fit(X_train, y_train)\n",
    "lgbm_train_time = time.time() - start\n",
    "\n",
    "# Mejor modelo encontrado\n",
    "best_lgbm = grid.best_estimator_\n",
    "\n",
    "start = time.time()\n",
    "y_pred_lgbm = best_lgbm.predict(X_test)\n",
    "lgbm_pred_time = time.time() - start\n",
    "\n",
    "rmse_lgbm = np.sqrt(mean_squared_error(y_test, y_pred_lgbm))\n",
    "print(f\"LightGBM - RECM: {rmse_lgbm:.2f}, Mejor combinación: {grid.best_params_}, Tiempo de entrenamiento: {lgbm_train_time:.2f}s, Tiempo de predicción: {lgbm_pred_time:.4f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comentarios\n",
    "\n",
    "En esta sección, se entrenaron y evaluaron varios modelos de regresión, incluyendo Regresión Lineal, Árbol de Decisión, Bosque Aleatorio y LightGBM con ajuste de hiperparámetros. Se compararon los modelos en términos de precisión (RECM) y tiempos de entrenamiento y predicción. Los resultados muestran que LightGBM y Bosque Aleatorio ofrecen un buen equilibrio entre precisión y velocidad, aunque la elección final debe considerar también la interpretabilidad y el contexto del problema. Es recomendable analizar más a fondo el modelo seleccionado y validar su desempeño en diferentes escenarios antes de implementarlo en producción.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análisis del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Análisis de los modelos entrenados:\n",
      "\n",
      "Comparación de la calidad (RECM) de los modelos:\n",
      "- Regresión Lineal: 6642435.23\n",
      "- Árbol de Decisión: 3485605.19\n",
      "- Bosque Aleatorio: 2591204.42\n",
      "- LightGBM: 1613.64\n",
      "\n",
      "El modelo con mejor desempeño (menor RECM) es: LightGBM\n",
      "\n",
      "Comparación de tiempos de entrenamiento y predicción:\n",
      "- Regresión Lineal: Entrenamiento = 3.88s, Predicción = 0.0864s\n",
      "- Árbol de Decisión: Entrenamiento = 3.33s, Predicción = 0.0530s\n",
      "- Bosque Aleatorio: Entrenamiento = 91.22s, Predicción = 0.3186s\n",
      "- LightGBM: Entrenamiento = 32.14s, Predicción = 0.1579s\n",
      "\n",
      "Conclusión:\n",
      "El modelo LightGBM ofrece el mejor equilibrio entre calidad y velocidad para este conjunto de datos. Sin embargo, es importante considerar el contexto del problema y la interpretabilidad del modelo al tomar la decisión final.\n"
     ]
    }
   ],
   "source": [
    "# Análisis de los resultados de los modelos\n",
    "\n",
    "print(\"Análisis de los modelos entrenados:\\n\")\n",
    "\n",
    "# Comparación de los valores de RECM\n",
    "print(\"Comparación de la calidad (RECM) de los modelos:\")\n",
    "print(f\"- Regresión Lineal: {rmse_lr:.2f}\")\n",
    "print(f\"- Árbol de Decisión: {rmse_dt:.2f}\")\n",
    "print(f\"- Bosque Aleatorio: {rmse_rf:.2f}\")\n",
    "print(f\"- LightGBM: {rmse_lgbm:.2f}\")\n",
    "\n",
    "# Identificar el mejor modelo según RECM\n",
    "mejor_rmse = min(rmse_lr, rmse_dt, rmse_rf, rmse_lgbm)\n",
    "if mejor_rmse == rmse_lr:\n",
    "    mejor_modelo = \"Regresión Lineal\"\n",
    "elif mejor_rmse == rmse_dt:\n",
    "    mejor_modelo = \"Árbol de Decisión\"\n",
    "elif mejor_rmse == rmse_rf:\n",
    "    mejor_modelo = \"Bosque Aleatorio\"\n",
    "else:\n",
    "    mejor_modelo = \"LightGBM\"\n",
    "\n",
    "print(f\"\\nEl modelo con mejor desempeño (menor RECM) es: {mejor_modelo}\")\n",
    "\n",
    "# Análisis de velocidad\n",
    "print(\"\\nComparación de tiempos de entrenamiento y predicción:\")\n",
    "print(f\"- Regresión Lineal: Entrenamiento = {lr_train_time:.2f}s, Predicción = {lr_pred_time:.4f}s\")\n",
    "print(f\"- Árbol de Decisión: Entrenamiento = {dt_train_time:.2f}s, Predicción = {dt_pred_time:.4f}s\")\n",
    "print(f\"- Bosque Aleatorio: Entrenamiento = {rf_train_time:.2f}s, Predicción = {rf_pred_time:.4f}s\")\n",
    "print(f\"- LightGBM: Entrenamiento = {lgbm_train_time:.2f}s, Predicción = {lgbm_pred_time:.4f}s\")\n",
    "\n",
    "print(\"\\nConclusión:\")\n",
    "print(f\"El modelo {mejor_modelo} ofrece el mejor equilibrio entre calidad y velocidad para este conjunto de datos. Sin embargo, es importante considerar el contexto del problema y la interpretabilidad del modelo al tomar la decisión final.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Observaciones:**  \n",
    "En esta sección se compararon distintos modelos de regresión en cuanto a precisión (RECM) y tiempos de entrenamiento/predicción. Se observó que LightGBM y Bosque Aleatorio presentan un buen desempeño general, aunque la elección final debe considerar también la interpretabilidad y el contexto de uso. Es recomendable validar el modelo seleccionado en diferentes escenarios antes de su implementación definitiva.\n",
    "\n",
    "## **Conclusión:**  \n",
    "No existe un modelo universalmente superior; la mejor opción depende de las necesidades específicas del problema y de los recursos disponibles. La evaluación integral de los modelos es clave para una toma de decisiones informada.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lista de control"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Escribe 'x' para verificar. Luego presiona Shift+Enter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x]  Jupyter Notebook está abierto\n",
    "- [ ]  El código no tiene errores- [ ]  Las celdas con el código han sido colocadas en orden de ejecución- [ ]  Los datos han sido descargados y preparados- [ ]  Los modelos han sido entrenados\n",
    "- [ ]  Se realizó el análisis de velocidad y calidad de los modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
