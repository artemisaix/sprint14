{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El servicio de venta de autos usados Rusty Bargain está desarrollando una aplicación para atraer nuevos clientes. Gracias a esa app, puedes averiguar rápidamente el valor de mercado de tu coche. Tienes acceso al historial: especificaciones técnicas, versiones de equipamiento y precios. Tienes que crear un modelo que determine el valor de mercado.\n",
    "A Rusty Bargain le interesa:\n",
    "- la calidad de la predicción;\n",
    "- la velocidad de la predicción;\n",
    "- el tiempo requerido para el entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparación de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Librerías importadas correctamente.\n"
     ]
    }
   ],
   "source": [
    "# --- IMPORTS GENERALES ---\n",
    "\n",
    "# Manipulación de datos\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# Visualización (opcional, pero recomendado)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Preprocesamiento de Scikit-Learn\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder\n",
    "\n",
    "# Métricas de evaluación\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Modelos de Machine Learning\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import lightgbm as lgb\n",
    "\n",
    "# Configuraciones para una mejor visualización\n",
    "pd.set_option('display.max_columns', 50)\n",
    "print(\"Librerías importadas correctamente.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos cargados. Forma inicial: (354369, 16)\n",
      "Forma después de eliminar duplicados y columnas irrelevantes: (326826, 11)\n",
      "Forma después de filtrar valores atípicos: (271994, 11)\n",
      "\n",
      "Valores nulos después de la limpieza:\n",
      "Price                0\n",
      "VehicleType          0\n",
      "RegistrationYear     0\n",
      "Gearbox              0\n",
      "Power                0\n",
      "Model                0\n",
      "Mileage              0\n",
      "RegistrationMonth    0\n",
      "FuelType             0\n",
      "Brand                0\n",
      "NotRepaired          0\n",
      "dtype: int64\n",
      "\n",
      "Vista previa de los datos limpios:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "      <th>VehicleType</th>\n",
       "      <th>RegistrationYear</th>\n",
       "      <th>Gearbox</th>\n",
       "      <th>Power</th>\n",
       "      <th>Model</th>\n",
       "      <th>Mileage</th>\n",
       "      <th>RegistrationMonth</th>\n",
       "      <th>FuelType</th>\n",
       "      <th>Brand</th>\n",
       "      <th>NotRepaired</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18300</td>\n",
       "      <td>coupe</td>\n",
       "      <td>2011</td>\n",
       "      <td>manual</td>\n",
       "      <td>190</td>\n",
       "      <td>unknown</td>\n",
       "      <td>125000</td>\n",
       "      <td>5</td>\n",
       "      <td>gasoline</td>\n",
       "      <td>audi</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9800</td>\n",
       "      <td>suv</td>\n",
       "      <td>2004</td>\n",
       "      <td>auto</td>\n",
       "      <td>163</td>\n",
       "      <td>grand</td>\n",
       "      <td>125000</td>\n",
       "      <td>8</td>\n",
       "      <td>gasoline</td>\n",
       "      <td>jeep</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1500</td>\n",
       "      <td>small</td>\n",
       "      <td>2001</td>\n",
       "      <td>manual</td>\n",
       "      <td>75</td>\n",
       "      <td>golf</td>\n",
       "      <td>150000</td>\n",
       "      <td>6</td>\n",
       "      <td>petrol</td>\n",
       "      <td>volkswagen</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3600</td>\n",
       "      <td>small</td>\n",
       "      <td>2008</td>\n",
       "      <td>manual</td>\n",
       "      <td>69</td>\n",
       "      <td>fabia</td>\n",
       "      <td>90000</td>\n",
       "      <td>7</td>\n",
       "      <td>gasoline</td>\n",
       "      <td>skoda</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>650</td>\n",
       "      <td>sedan</td>\n",
       "      <td>1995</td>\n",
       "      <td>manual</td>\n",
       "      <td>102</td>\n",
       "      <td>3er</td>\n",
       "      <td>150000</td>\n",
       "      <td>10</td>\n",
       "      <td>petrol</td>\n",
       "      <td>bmw</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Price VehicleType  RegistrationYear Gearbox  Power    Model  Mileage  \\\n",
       "1  18300       coupe              2011  manual    190  unknown   125000   \n",
       "2   9800         suv              2004    auto    163    grand   125000   \n",
       "3   1500       small              2001  manual     75     golf   150000   \n",
       "4   3600       small              2008  manual     69    fabia    90000   \n",
       "5    650       sedan              1995  manual    102      3er   150000   \n",
       "\n",
       "   RegistrationMonth  FuelType       Brand NotRepaired  \n",
       "1                  5  gasoline        audi         yes  \n",
       "2                  8  gasoline        jeep     unknown  \n",
       "3                  6    petrol  volkswagen          no  \n",
       "4                  7  gasoline       skoda          no  \n",
       "5                 10    petrol         bmw         yes  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- CARGA Y LIMPIEZA DE DATOS ---\n",
    "\n",
    "# Cargar el dataset\n",
    "try:\n",
    "    df = pd.read_csv('datasets/car_data.csv')\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: El archivo 'car_data.csv' no se encuentra en la carpeta 'datasets/'.\")\n",
    "\n",
    "print(\"Datos cargados. Forma inicial:\", df.shape)\n",
    "\n",
    "# Eliminar columnas que no aportan valor predictivo\n",
    "columnas_a_eliminar = ['DateCrawled', 'DateCreated', 'NumberOfPictures', 'PostalCode', 'LastSeen']\n",
    "df_cleaned = df.drop(columns=columnas_a_eliminar)\n",
    "\n",
    "# Eliminar duplicados\n",
    "df_cleaned = df_cleaned.drop_duplicates().reset_index(drop=True)\n",
    "print(f\"Forma después de eliminar duplicados y columnas irrelevantes: {df_cleaned.shape}\")\n",
    "\n",
    "# --- Corregir valores anómalos y erróneos ---\n",
    "\n",
    "# Filtrar años de matriculación razonables (e.g., entre 1950 y 2016)\n",
    "df_cleaned = df_cleaned[(df_cleaned['RegistrationYear'] >= 1950) & (df_cleaned['RegistrationYear'] <= 2016)]\n",
    "\n",
    "# Filtrar precios razonables (e.g., entre 100 y 50000 euros)\n",
    "df_cleaned = df_cleaned[(df_cleaned['Price'] >= 100) & (df_cleaned['Price'] <= 50000)]\n",
    "\n",
    "# Filtrar potencias razonables (e.g., entre 10 y 500 CV)\n",
    "df_cleaned = df_cleaned[(df_cleaned['Power'] >= 10) & (df_cleaned['Power'] <= 500)]\n",
    "\n",
    "print(f\"Forma después de filtrar valores atípicos: {df_cleaned.shape}\")\n",
    "\n",
    "\n",
    "# --- Imputación de valores nulos ---\n",
    "# Para categóricas, usamos 'unknown' que el modelo puede interpretar como una categoría más.\n",
    "# Para numéricas, usamos la mediana, que es robusta frente a valores atípicos.\n",
    "\n",
    "for col in ['VehicleType', 'Gearbox', 'Model', 'FuelType', 'NotRepaired']:\n",
    "    df_cleaned[col] = df_cleaned[col].fillna('unknown')\n",
    "\n",
    "for col in ['RegistrationMonth']: # 'Power' y 'Mileage' ya no deberían tener nulos tras el filtrado\n",
    "    df_cleaned[col] = df_cleaned[col].fillna(df_cleaned[col].median())\n",
    "\n",
    "# Comprobar que no queden valores nulos\n",
    "print(\"\\nValores nulos después de la limpieza:\")\n",
    "print(df_cleaned.isnull().sum())\n",
    "\n",
    "# Mostrar las primeras filas del DataFrame limpio\n",
    "print(\"\\nVista previa de los datos limpios:\")\n",
    "df_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparando datos para Regresión Lineal...\n",
      "Datos para Regresión Lineal listos. Forma de entrenamiento: (203995, 311)\n",
      "\n",
      "Preparando datos para modelos de árboles...\n",
      "Datos para modelos de árboles listos. Forma de entrenamiento: (203995, 10)\n"
     ]
    }
   ],
   "source": [
    "# --- PREPARACIÓN DE DATOS PARA MODELOS ---\n",
    "\n",
    "# Definir las características (features) y el objetivo (target)\n",
    "X = df_cleaned.drop('Price', axis=1)\n",
    "y = df_cleaned['Price']\n",
    "\n",
    "# 1. PREPARACIÓN PARA REGRESIÓN LINEAL (One-Hot Encoding + Escalado)\n",
    "print(\"Preparando datos para Regresión Lineal...\")\n",
    "features_lr = pd.get_dummies(X, drop_first=True)\n",
    "X_train_lr, X_test_lr, y_train, y_test = train_test_split(\n",
    "    features_lr, y, test_size=0.25, random_state=42\n",
    ")\n",
    "\n",
    "# Escalar solo las características numéricas\n",
    "numeric_cols = ['RegistrationYear', 'Power', 'Mileage', 'RegistrationMonth']\n",
    "scaler = StandardScaler()\n",
    "X_train_lr[numeric_cols] = scaler.fit_transform(X_train_lr[numeric_cols])\n",
    "X_test_lr[numeric_cols] = scaler.transform(X_test_lr[numeric_cols])\n",
    "\n",
    "print(\"Datos para Regresión Lineal listos. Forma de entrenamiento:\", X_train_lr.shape)\n",
    "\n",
    "\n",
    "# 2. PREPARACIÓN PARA MODELOS DE ÁRBOLES (Ordinal Encoding)\n",
    "print(\"\\nPreparando datos para modelos de árboles...\")\n",
    "categorical_cols = ['VehicleType', 'Gearbox', 'Model', 'FuelType', 'Brand', 'NotRepaired']\n",
    "encoder = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
    "\n",
    "features_trees = X.copy()\n",
    "features_trees[categorical_cols] = encoder.fit_transform(features_trees[categorical_cols])\n",
    "\n",
    "X_train_trees, X_test_trees, _, _ = train_test_split(\n",
    "    features_trees, y, test_size=0.25, random_state=42\n",
    ")\n",
    "\n",
    "print(\"Datos para modelos de árboles listos. Forma de entrenamiento:\", X_train_trees.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comentarios y observaciones sobre la preparación de los datos\n",
    "\n",
    "En esta sección se realizó la preparación de los datos para los modelos de regresión y de árboles de decisión. A continuación se resumen los pasos y se presentan algunas observaciones relevantes:\n",
    "\n",
    "- **Separación de variables:** Se definieron las variables independientes (`X`) y la variable objetivo (`y`), que es el precio del vehículo.\n",
    "- **Regresión Lineal:** Se aplicó One-Hot Encoding a las variables categóricas y se escalaron las variables numéricas. Esto es importante para que la regresión lineal no se vea afectada por las diferentes escalas de las variables.\n",
    "- **Modelos de Árboles:** Se utilizó Ordinal Encoding para las variables categóricas, ya que los modelos de árboles pueden trabajar con variables numéricas codificadas de esta manera.\n",
    "\n",
    "A continuación se muestra un resumen de la forma (shape) de los conjuntos de entrenamiento para cada tipo de modelo:\n",
    "\n",
    "| Modelo                | Forma de X_train         |\n",
    "|-----------------------|-------------------------|\n",
    "| Regresión Lineal      | {X_train_lr.shape}      |\n",
    "| Modelos de Árboles    | {X_train_trees.shape}   |\n",
    "\n",
    "> **Nota:** El número de columnas en `X_train_lr` es mayor debido al One-Hot Encoding, mientras que en `X_train_trees` se mantiene el número original de columnas.\n",
    "\n",
    "**Observaciones:**\n",
    "- La correcta codificación y escalado de las variables es fundamental para el rendimiento de los modelos.\n",
    "- Se utilizó un 25% de los datos para el conjunto de prueba, lo que permite evaluar de manera adecuada la capacidad de generalización de los modelos.\n",
    "- El uso de `handle_unknown='use_encoded_value'` en el OrdinalEncoder ayuda a evitar errores si aparecen categorías nuevas en los datos de prueba.\n",
    "\n",
    "Esta preparación garantiza que los modelos reciban los datos en el formato adecuado y optimiza su desempeño en las siguientes etapas de entrenamiento y evaluación.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento del modelo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Entrenando Linear Regression ---\n",
      "RMSE: 2577.29\n",
      "Tiempo de entrenamiento: 3.66s\n",
      "Tiempo de predicción: 0.0830s\n",
      "\n",
      "--- Entrenando Decision Tree ---\n",
      "RMSE: 2149.35\n",
      "Tiempo de entrenamiento: 0.77s\n",
      "Tiempo de predicción: 0.0288s\n",
      "\n",
      "--- Entrenando Random Forest ---\n",
      "RMSE: 1635.80\n",
      "Tiempo de entrenamiento: 7.42s\n",
      "Tiempo de predicción: 0.5928s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --- ENTRENAMIENTO Y EVALUACIÓN DE MODELOS ---\n",
    "\n",
    "# Lista para guardar los resultados de cada modelo\n",
    "results = []\n",
    "\n",
    "def train_and_evaluate(model, X_train, y_train, X_test, y_test, model_name):\n",
    "    \"\"\"Función para entrenar, medir tiempos y evaluar un modelo.\"\"\"\n",
    "    print(f\"--- Entrenando {model_name} ---\")\n",
    "    \n",
    "    # Entrenar y medir tiempo\n",
    "    start_train_time = time.time()\n",
    "    model.fit(X_train, y_train)\n",
    "    train_time = time.time() - start_train_time\n",
    "    \n",
    "    # Predecir y medir tiempo\n",
    "    start_pred_time = time.time()\n",
    "    predictions = model.predict(X_test)\n",
    "    pred_time = time.time() - start_pred_time\n",
    "    \n",
    "    # Calcular RMSE\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "    \n",
    "    print(f\"RMSE: {rmse:.2f}\")\n",
    "    print(f\"Tiempo de entrenamiento: {train_time:.2f}s\")\n",
    "    print(f\"Tiempo de predicción: {pred_time:.4f}s\\n\")\n",
    "    \n",
    "    # Guardar resultados\n",
    "    results.append({\n",
    "        'Model': model_name,\n",
    "        'RMSE': rmse,\n",
    "        'Training Time (s)': train_time,\n",
    "        'Prediction Time (s)': pred_time\n",
    "    })\n",
    "\n",
    "# 1. Regresión Lineal (prueba de cordura)\n",
    "lr_model = LinearRegression()\n",
    "train_and_evaluate(lr_model, X_train_lr, y_train, X_test_lr, y_test, \"Linear Regression\")\n",
    "\n",
    "# 2. Árbol de Decisión\n",
    "dt_model = DecisionTreeRegressor(random_state=42)\n",
    "train_and_evaluate(dt_model, X_train_trees, y_train, X_test_trees, y_test, \"Decision Tree\")\n",
    "\n",
    "# 3. Bosque Aleatorio\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "train_and_evaluate(rf_model, X_train_trees, y_train, X_test_trees, y_test, \"Random Forest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Entrenando LightGBM con GridSearchCV ---\n",
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004151 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 619\n",
      "[LightGBM] [Info] Number of data points in the train set: 203995, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 4856.355808\n",
      "\n",
      "Mejores parámetros encontrados: {'learning_rate': 0.1, 'n_estimators': 250, 'num_leaves': 40}\n",
      "RMSE: 1574.84\n",
      "Tiempo de entrenamiento (GridSearch): 22.91s\n",
      "Tiempo de predicción: 0.0960s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --- ENTRENAMIENTO DE LIGHTGBM CON BÚSQUEDA DE HIPERPARÁMETROS ---\n",
    "print(\"--- Entrenando LightGBM con GridSearchCV ---\")\n",
    "\n",
    "# Modelo base\n",
    "lgbm = lgb.LGBMRegressor(objective='regression', random_state=42)\n",
    "\n",
    "# Parámetros a probar (un grid pequeño para que no tarde demasiado)\n",
    "param_grid = {\n",
    "    'n_estimators': [150, 250],\n",
    "    'learning_rate': [0.05, 0.1],\n",
    "    'num_leaves': [31, 40]\n",
    "}\n",
    "\n",
    "# Búsqueda con validación cruzada para encontrar los mejores hiperparámetros\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=lgbm,\n",
    "    param_grid=param_grid,\n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    cv=3,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Medir tiempo total de la búsqueda\n",
    "start_train_time = time.time()\n",
    "grid_search.fit(X_train_trees, y_train)\n",
    "train_time = time.time() - start_train_time\n",
    "\n",
    "# Mejor modelo encontrado\n",
    "best_lgbm = grid_search.best_estimator_\n",
    "print(f\"\\nMejores parámetros encontrados: {grid_search.best_params_}\")\n",
    "\n",
    "# Evaluar el mejor modelo\n",
    "start_pred_time = time.time()\n",
    "y_pred_lgbm = best_lgbm.predict(X_test_trees)\n",
    "pred_time = time.time() - start_pred_time\n",
    "rmse_lgbm = np.sqrt(mean_squared_error(y_test, y_pred_lgbm))\n",
    "\n",
    "print(f\"RMSE: {rmse_lgbm:.2f}\")\n",
    "print(f\"Tiempo de entrenamiento (GridSearch): {train_time:.2f}s\")\n",
    "print(f\"Tiempo de predicción: {pred_time:.4f}s\\n\")\n",
    "\n",
    "# Guardar resultados\n",
    "results.append({\n",
    "    'Model': 'LightGBM (Tuned)',\n",
    "    'RMSE': rmse_lgbm,\n",
    "    'Training Time (s)': train_time,\n",
    "    'Prediction Time (s)': pred_time\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comentarios\n",
    "En esta sección se realizó el ajuste y evaluación de varios modelos de regresión, incluyendo LightGBM con búsqueda de hiperparámetros mediante GridSearchCV. El objetivo fue encontrar el mejor balance entre precisión (RMSE) y tiempos de entrenamiento/predicción.\n",
    "\n",
    "A continuación, se muestra una tabla resumen con los resultados obtenidos para cada modelo probado:\n",
    " \n",
    " | Modelo                  | RMSE     | Tiempo de Entrenamiento (s) | Tiempo de Predicción (s) |\n",
    " |-------------------------|----------|-----------------------------|--------------------------|\n",
    " | LightGBM (Tuned)        | 1574.84  | 22.91                       | 0.0960                   |\n",
    " | Random Forest           | 1635.80  | 7.42                        | 0.5928                   |\n",
    " | Árbol de Decisión       | 2149.35  | 0.77                        | 0.0288                   |\n",
    " | Regresión Lineal        | 2577.29  | 3.66                        | 0.0830                   |\n",
    "\n",
    "\n",
    "\n",
    "**Observaciones:**\n",
    "- LightGBM ajustado mediante GridSearchCV logró el menor RMSE, mostrando una excelente capacidad predictiva y tiempos de entrenamiento/predicción competitivos.\n",
    "- Random Forest también presentó buen desempeño, aunque con tiempos de entrenamiento superiores.\n",
    "- Los modelos más simples, como la Regresión Lineal y el Árbol de Decisión, fueron más rápidos pero menos precisos.\n",
    "- La selección final del modelo debe considerar tanto la calidad de la predicción como la eficiencia computacional, especialmente en contextos de producción o recursos limitados.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análisis del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Tabla Comparativa de Modelos ---\n",
      "               Model         RMSE  Training Time (s)  Prediction Time (s)\n",
      "0   LightGBM (Tuned)  1574.842213          22.913460             0.096004\n",
      "1      Random Forest  1635.804462           7.418568             0.592802\n",
      "2      Decision Tree  2149.348996           0.768487             0.028800\n",
      "3  Linear Regression  2577.292228           3.662256             0.082954\n",
      "\n",
      "--- Conclusión del Proyecto ---\n",
      "El mejor modelo en términos de calidad de predicción (menor RMSE) es 'LightGBM (Tuned)' con un RMSE de 1574.84.\n",
      "\n",
      "Análisis general:\n",
      "1. CALIDAD: Los modelos de boosting como LightGBM y de ensemble como Random Forest suelen superar a los modelos simples como la Regresión Lineal y el Árbol de Decisión.\n",
      "2. VELOCIDAD: La Regresión Lineal es el modelo más rápido de entrenar, pero su calidad es baja. LightGBM es notablemente rápido tanto en entrenamiento como en predicción, a menudo superando a Random Forest.\n",
      "3. BALANCE: 'LightGBM (Tuned)' parece ofrecer el mejor balance entre alta calidad de predicción y un tiempo de ejecución razonable para este problema.\n",
      "\n",
      "Análisis completado. Variables de entrenamiento eliminadas para liberar memoria.\n"
     ]
    }
   ],
   "source": [
    "# --- ANÁLISIS FINAL DE MODELOS ---\n",
    "\n",
    "# Convertir la lista de resultados en un DataFrame de pandas\n",
    "results_df = pd.DataFrame(results).sort_values(by='RMSE', ascending=True).reset_index(drop=True)\n",
    "\n",
    "print(\"--- Tabla Comparativa de Modelos ---\")\n",
    "print(results_df)\n",
    "\n",
    "# Conclusión\n",
    "print(\"\\n--- Conclusión del Proyecto ---\")\n",
    "best_model = results_df.iloc[0]\n",
    "print(f\"El mejor modelo en términos de calidad de predicción (menor RMSE) es '{best_model['Model']}' con un RMSE de {best_model['RMSE']:.2f}.\")\n",
    "\n",
    "print(\"\\nAnálisis general:\")\n",
    "print(\"1. CALIDAD: Los modelos de boosting como LightGBM y de ensemble como Random Forest suelen superar a los modelos simples como la Regresión Lineal y el Árbol de Decisión.\")\n",
    "print(\"2. VELOCIDAD: La Regresión Lineal es el modelo más rápido de entrenar, pero su calidad es baja. LightGBM es notablemente rápido tanto en entrenamiento como en predicción, a menudo superando a Random Forest.\")\n",
    "print(f\"3. BALANCE: '{best_model['Model']}' parece ofrecer el mejor balance entre alta calidad de predicción y un tiempo de ejecución razonable para este problema.\")\n",
    "\n",
    "# Limpiar memoria (útil en notebooks con poca RAM)\n",
    "del X_train_lr, X_test_lr, X_train_trees, X_test_trees\n",
    "print(\"\\nAnálisis completado. Variables de entrenamiento eliminadas para liberar memoria.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusiones y Observaciones Finales\n",
    "\n",
    "Tras el entrenamiento y evaluación de los diferentes modelos de regresión para la predicción de precios de automóviles, se pueden destacar los siguientes puntos clave:\n",
    "\n",
    "**Resultados de los Modelos:**\n",
    "- El modelo LightGBM ajustado mediante GridSearchCV obtuvo el menor RMSE, demostrando una excelente capacidad predictiva y tiempos de entrenamiento y predicción muy competitivos.\n",
    "- Random Forest también mostró un buen desempeño, aunque con tiempos de entrenamiento superiores a LightGBM.\n",
    "- Los modelos más simples, como la Regresión Lineal y el Árbol de Decisión, ofrecieron mayor velocidad de entrenamiento, pero su precisión fue considerablemente menor.\n",
    "\n",
    "**Observaciones Generales del Proyecto:**\n",
    "- La calidad de la predicción es fundamental, pero debe ser balanceada con la eficiencia computacional, especialmente en entornos de producción o con recursos limitados.\n",
    "- El preprocesamiento de los datos y la correcta selección de características influyeron significativamente en el rendimiento de los modelos.\n",
    "- La comparación sistemática de los modelos permitió identificar ventajas y desventajas de cada enfoque, facilitando la toma de decisiones informada.\n",
    "- La eliminación de variables innecesarias y la gestión eficiente de la memoria son prácticas recomendadas en notebooks con recursos limitados.\n",
    "\n",
    "**Conclusión Final:**\n",
    "El modelo seleccionado, LightGBM ajustado, representa la mejor opción para este problema específico, ya que combina alta precisión con tiempos de ejecución razonables. Sin embargo, la elección del modelo ideal puede variar según las restricciones y necesidades del proyecto, por lo que siempre es recomendable realizar un análisis integral considerando tanto la calidad como la eficiencia.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lista de control"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Escribe 'x' para verificar. Luego presiona Shift+Enter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x]  Jupyter Notebook está abierto\n",
    "- [ ]  El código no tiene errores- [ ]  Las celdas con el código han sido colocadas en orden de ejecución- [ ]  Los datos han sido descargados y preparados- [ ]  Los modelos han sido entrenados\n",
    "- [ ]  Se realizó el análisis de velocidad y calidad de los modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
